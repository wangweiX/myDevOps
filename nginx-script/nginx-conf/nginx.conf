# run user and group
user nginx nginx;

# you must set worker processes based on your CPU cores, nginx does not benefit from setting more than that
# some last versions calculate it automatically
worker_processes  auto;

# number of file descriptors used for nginx
# the limit for the maximum FDs on the server is usually set by the OS.
# if you don't set FD's then OS settings will be used which is by default 2000
worker_rlimit_nofile  65535;

# error log lever [ debug | info | notice | warn | error | crit ]
error_log  /var/log/nginx/error.log error;

# pid file path
pid   /var/run/nginx.pid;
# enables profiling of nginx worker processes
google_perftools_profiles /tmp/nginx_profile;

# load nginx modules
load_module "/usr/lib/nginx/modules/ngx_http_naxsi_module.so";
#load_module "/usr/lib/nginx/modules/ngx_pagespeed.so";
#load_module "/usr/lib/nginx/modules/ngx_http_geoip_module.so";
#load_module "/usr/lib/nginx/modules/ngx_http_image_filter_module.so";
#load_module "/usr/lib/nginx/modules/ngx_http_xslt_filter_module.so";
#load_module "/usr/lib/nginx/modules/ngx_mail_module.so";
#load_module "/usr/lib/nginx/modules/ngx_stream_geoip_module.so";
#load_module "/usr/lib/nginx/modules/ngx_stream_module.so";

# provides the configuration file context in which the directives that affect connection processing are specified.
events {
    # determines how much clients will be served per worker
    # max clients = worker_connections * worker_processes
    # max clients is also limited by the number of socket connections available on the system (~64k)
    worker_connections  65535;

    # optmized to serve many clients with each thread, essential for linux -- for testing environment
    use epoll;

    # accept as many connections as possible, may flood worker connections if set too low -- for testing environment
    multi_accept on;
}

http {
    include       mime.types;
    default_type  application/octet-stream;

    log_format  main  '$remote_addr $remote_user [$time_local] "$request" $status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for" $gzip_ratio $request_time $bytes_sent $request_length';
        
    access_log  /var/log/nginx/access.log  main buffer=32k;

    # cache informations about FDs, frequently accessed files can boost performance, but you need to test those values
    open_file_cache max=200000 inactive=20s; 
    open_file_cache_valid 30s; 
    open_file_cache_min_uses 2;
    open_file_cache_errors on;

    # copies data between one FD and other from within the kernel
    # faster then read() + write()
    sendfile        on;

    # send headers in one peace, its better then sending them one by one 
    tcp_nopush     on;

    # don't buffer data sent, good for small data bursts in real time
    tcp_nodelay  on;

    server_tokens off;

    # allow the server to close connection on non responding client, this will free up memory
    reset_timedout_connection on;

    # # read timeout for the request body from client -- default 60
    client_body_timeout   10;
    # if client stop responding, free up memory -- default 60
    send_timeout          2;
    # server will close connection after this time -- default 75
    keepalive_timeout     30;
    # number of requests client can make over keep-alive -- for testing environment
    keepalive_requests 100000;

    # headerbuffer size for the request header from client -- for testing environment
    client_header_buffer_size    1k;
    # maximum number and size of buffers for large headers to read from client request
    large_client_header_buffers  2 1k;
    # if the request body size is more than the buffer size, then the entire (or partial)
    # request body is written into a temporary file
    client_body_buffer_size      1k;
    client_max_body_size         2M;
    # how long to wait for the client to send a request header -- for testing environment
    client_header_timeout        10;

    # get user real ip
    # If load balancing is configured upstream of Nginx, e.g: SLB/NLB or cloudflare, we should get real ip from them
    # set_real_ip_from slbip/cloudflareip ;
    real_ip_header X-Forwarded-For;

    # If the ip address is a whitelist address, then $limit is 0, otherwise $limit is 1.
    geo $limit {
        default 1;
        10.0.0.0/8 0;
        192.168.0.0/24 0;
    }
    
    # If $limit is 0, $limit_key is set to the empty string
    # If $limit is 1, $limit_key is set to the client’s IP address in binary format
    map $limit $limit_key {
        0 "";
        1 $binary_remote_addr;
    }

    # limit the number of connections per single IP
    limit_conn_zone $limit_key zone=conn_limit_5:5m;
    limit_conn_zone $binary_remote_addr zone=conn_limit_wl:15m;

    ## limit requests per ip address
    # The address not in the ip whitelist is given a strictly limit：1 ~ 5r/s
    limit_req_zone $limit_key zone=req_limit_qps1:10m rate=1r/s;
    limit_req_zone $limit_key zone=req_limit_qps3:10m rate=3r/s;
    limit_req_zone $limit_key zone=req_limit_qps5:10m rate=5r/s;
    # The address in the ip whitelist is given a loose limit：15r/s
    limit_req_zone $binary_remote_addr zone=req_limit_wl:10m rate=15r/s;

    # config Load balancing
    #upstream server_upstream {
    #  server server_ip1:port1 weight=10;
    #  server server_ip2:port2 weight=10;
    #}
    
    # include nginx site config
    include conf.d/*.conf;
    include sites-enabled/*.conf; 
    include naxsi_core.rules;
}
